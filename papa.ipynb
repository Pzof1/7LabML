{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Обработка и анализ данных",
   "id": "793044d2e930d728"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_path = '/Users/pzof/Downloads/ml-100k/ua.base'\n",
    "test_path  = '/Users/pzof/Downloads/ml-100k/ua.test'\n",
    "cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "train_data = pd.read_csv(train_path, sep='\\t', names=cols, header=None)\n",
    "test_data  = pd.read_csv(test_path,  sep='\\t', names=cols, header=None)\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape: \", test_data.shape)\n",
    "\n",
    "n_users = train_data['user_id'].nunique()\n",
    "n_items = train_data['item_id'].nunique()\n",
    "print(f\"Число уникальных пользователей (train): {n_users}\")\n",
    "print(f\"Число уникальных фильмов (train): {n_items}\")\n",
    "\n",
    "# Гистограммы распределения\n",
    "user_cnt = train_data.groupby('user_id')['item_id'].count()\n",
    "item_cnt = train_data.groupby('item_id')['user_id'].count()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(user_cnt, bins=30, kde=False)\n",
    "plt.title(\"Распределение кол-ва оценок на пользователя (train)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(item_cnt, bins=30, kde=False)\n",
    "plt.title(\"Распределение кол-ва оценок на фильм (train)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='rating', data=train_data, order=sorted(train_data['rating'].unique()))\n",
    "plt.title(\"Распределение рейтингов (train)\")\n",
    "plt.show()\n",
    "\n",
    "# Переиндексация и сплит на train/val\n",
    "unique_users = train_data['user_id'].unique()\n",
    "unique_items = train_data['item_id'].unique()\n",
    "\n",
    "user_to_idx = {u: i for i, u in enumerate(unique_users)}\n",
    "item_to_idx = {m: i for i, m in enumerate(unique_items)}\n",
    "\n",
    "train_data['user_idx'] = train_data['user_id'].map(user_to_idx)\n",
    "train_data['item_idx'] = train_data['item_id'].map(item_to_idx)\n",
    "\n",
    "# Убираем из test тех, кого нет в train\n",
    "test_data = test_data[\n",
    "    test_data['user_id'].isin(unique_users) &\n",
    "    test_data['item_id'].isin(unique_items)\n",
    "].copy()\n",
    "test_data['user_idx'] = test_data['user_id'].map(user_to_idx)\n",
    "test_data['item_idx'] = test_data['item_id'].map(item_to_idx)\n",
    "\n",
    "num_users_train = len(unique_users)\n",
    "num_items_train = len(unique_items)\n",
    "print(f\"num_users: {num_users_train}, num_items: {num_items_train}\")\n",
    "\n",
    "val_frac = 0.1\n",
    "val_size = int(len(train_data) * val_frac)\n",
    "val_df   = train_data.iloc[:val_size].copy()\n",
    "train_df = train_data.iloc[val_size:].copy()"
   ],
   "id": "d3ae9ff2c430af2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Сама модель\n",
    "Мы используем матричную факторизацию с биасами (user/item bias) и латентными эмбеддингами (размерность n_factors обучаемую через mini-batch Adam (с гиперпараметрами lr, beta1, beta2, eps) и L2-регуляризацию (reg_emb, reg_bias). Для предотвращения переобучения вводим early stopping (отслеживая RMSE на валидации), а для подбора гиперпараметров (n_factors, lr, reg_emb) используем grid search по валидационному RMSE. После обучения вычисляем метрики Precision@k, Recall@k на тесте (с порогом релевантности), а также визуализируем обученные эмбеддинги пользователей и фильмов с помощью UMAP и t-SNE (четыре отдельные графика: UMAP-users, UMAP-items, t-SNE-users, t-SNE-items)."
   ],
   "id": "bbe5bf5a60c3f184"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class AdamOptimizer:\n",
    "    def __init__(self, shape, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.m = np.zeros(shape, dtype=np.float32)\n",
    "        self.v = np.zeros(shape, dtype=np.float32)\n",
    "        self.t = 0\n",
    "\n",
    "    def update(self, w, grad):\n",
    "        self.t += 1\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * grad\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (grad ** 2)\n",
    "        m_hat = self.m / (1 - self.beta1 ** self.t)\n",
    "        v_hat = self.v / (1 - self.beta2 ** self.t)\n",
    "        w -= self.lr * m_hat / (np.sqrt(v_hat) + self.eps)\n",
    "\n",
    "class MatrixFactorizationWithBiases:\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_users,\n",
    "            num_items,\n",
    "            n_factors=40,\n",
    "            lr=0.005,\n",
    "            beta1=0.9,\n",
    "            beta2=0.999,\n",
    "            eps=1e-8,\n",
    "            reg_emb=0.02,\n",
    "            reg_bias=0.01,\n",
    "            n_epochs=30,\n",
    "            batch_size=1024,\n",
    "            early_stopping_patience=3,\n",
    "            seed=42\n",
    "    ):\n",
    "        np.random.seed(seed)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.reg_emb = reg_emb\n",
    "        self.reg_bias = reg_bias\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "\n",
    "        self.mu = 0.\n",
    "        self.b_u = np.zeros(num_users, dtype=np.float32)\n",
    "        self.b_i = np.zeros(num_items, dtype=np.float32)\n",
    "\n",
    "        self.P = 0.01 * np.random.randn(num_users, n_factors).astype(np.float32)\n",
    "        self.Q = 0.01 * np.random.randn(num_items, n_factors).astype(np.float32)\n",
    "\n",
    "        # Adam для каждого массива\n",
    "        self.opt_b_u = AdamOptimizer(self.b_u.shape, lr=self.lr, beta1=self.beta1, beta2=self.beta2, eps=self.eps)\n",
    "        self.opt_b_i = AdamOptimizer(self.b_i.shape, lr=self.lr, beta1=self.beta1, beta2=self.beta2, eps=self.eps)\n",
    "        self.opt_P   = AdamOptimizer(self.P.shape,   lr=self.lr, beta1=self.beta1, beta2=self.beta2, eps=self.eps)\n",
    "        self.opt_Q   = AdamOptimizer(self.Q.shape,   lr=self.lr, beta1=self.beta1, beta2=self.beta2, eps=self.eps)\n",
    "\n",
    "    def fit(self, df_train, df_val=None):\n",
    "        # Глобальное среднее\n",
    "        self.mu = df_train['rating'].mean()\n",
    "\n",
    "        train_users   = df_train['user_idx'].values\n",
    "        train_items   = df_train['item_idx'].values\n",
    "        train_ratings = df_train['rating'].values.astype(np.float32)\n",
    "\n",
    "        if df_val is not None:\n",
    "            val_users   = df_val['user_idx'].values\n",
    "            val_items   = df_val['item_idx'].values\n",
    "            val_ratings = df_val['rating'].values.astype(np.float32)\n",
    "\n",
    "        best_val_rmse = float('inf')\n",
    "        no_improve_count = 0\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            perm = np.random.permutation(len(df_train))\n",
    "            batch_start = 0\n",
    "            while batch_start < len(df_train):\n",
    "                batch_end = min(batch_start + self.batch_size, len(df_train))\n",
    "                batch_idx = perm[batch_start:batch_end]\n",
    "\n",
    "                bu = train_users[batch_idx]\n",
    "                bi = train_items[batch_idx]\n",
    "                r  = train_ratings[batch_idx]\n",
    "\n",
    "                pred = (self.mu\n",
    "                        + self.b_u[bu]\n",
    "                        + self.b_i[bi]\n",
    "                        + np.sum(self.P[bu] * self.Q[bi], axis=1))\n",
    "\n",
    "                err = r - pred\n",
    "\n",
    "                grad_b_u = -err + self.reg_bias * self.b_u[bu]\n",
    "                grad_b_i = -err + self.reg_bias * self.b_i[bi]\n",
    "                grad_P   = -(err[:, None] * self.Q[bi]) + self.reg_emb * self.P[bu]\n",
    "                grad_Q   = -(err[:, None] * self.P[bu]) + self.reg_emb * self.Q[bi]\n",
    "\n",
    "                # формируем полные вектора\n",
    "                grad_b_u_full = np.zeros_like(self.b_u)\n",
    "                np.add.at(grad_b_u_full, bu, grad_b_u)\n",
    "\n",
    "                grad_b_i_full = np.zeros_like(self.b_i)\n",
    "                np.add.at(grad_b_i_full, bi, grad_b_i)\n",
    "\n",
    "                grad_P_full = np.zeros_like(self.P)\n",
    "                for i, user_idx in enumerate(bu):\n",
    "                    grad_P_full[user_idx] += grad_P[i]\n",
    "\n",
    "                grad_Q_full = np.zeros_like(self.Q)\n",
    "                for i, item_idx in enumerate(bi):\n",
    "                    grad_Q_full[item_idx] += grad_Q[i]\n",
    "\n",
    "                # Обновляем\n",
    "                self.opt_b_u.update(self.b_u, grad_b_u_full)\n",
    "                self.opt_b_i.update(self.b_i, grad_b_i_full)\n",
    "                self.opt_P.update(self.P, grad_P_full)\n",
    "                self.opt_Q.update(self.Q, grad_Q_full)\n",
    "\n",
    "                batch_start = batch_end\n",
    "\n",
    "            # Логируем RMSE\n",
    "            train_rmse = self.evaluate_rmse(df_train)\n",
    "            if df_val is not None:\n",
    "                val_rmse = self.evaluate_rmse(df_val)\n",
    "                print(f\"Epoch {epoch+1}/{self.n_epochs}, \"\n",
    "                      f\"Train RMSE={train_rmse:.4f}, Val RMSE={val_rmse:.4f}\")\n",
    "\n",
    "                if val_rmse < best_val_rmse - 1e-6:\n",
    "                    best_val_rmse = val_rmse\n",
    "                    no_improve_count = 0\n",
    "                else:\n",
    "                    no_improve_count += 1\n",
    "                    if no_improve_count >= self.early_stopping_patience:\n",
    "                        print(\"Early stopping triggered!\")\n",
    "                        break\n",
    "            else:\n",
    "                print(f\"Epoch {epoch+1}/{self.n_epochs}, Train RMSE={train_rmse:.4f}\")\n",
    "\n",
    "    def evaluate_rmse(self, df):\n",
    "        users = df['user_idx'].values\n",
    "        items = df['item_idx'].values\n",
    "        true_ratings = df['rating'].values\n",
    "        preds = (self.mu\n",
    "                 + self.b_u[users]\n",
    "                 + self.b_i[items]\n",
    "                 + np.sum(self.P[users] * self.Q[items], axis=1))\n",
    "        mse = np.mean((true_ratings - preds) ** 2)\n",
    "        return math.sqrt(mse)\n",
    "\n",
    "    def predict(self, user_idx, item_idx):\n",
    "        return float(self.mu\n",
    "                     + self.b_u[user_idx]\n",
    "                     + self.b_i[item_idx]\n",
    "                     + np.dot(self.P[user_idx], self.Q[item_idx]))\n",
    "\n",
    "    def recommend_for_user(self, user_idx, N=10):\n",
    "        scores = (self.mu\n",
    "                  + self.b_u[user_idx]\n",
    "                  + self.b_i\n",
    "                  + np.dot(self.P[user_idx], self.Q.T))\n",
    "        return np.argsort(scores)[::-1][:N]"
   ],
   "id": "c6b3774de8135469"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "перебор гиперпараметров",
   "id": "4e808b64b635e0a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_experiment(params):\n",
    "    \"\"\"\n",
    "    Обучаем модель с заданными params, возвращаем (val_rmse, model).\n",
    "    \"\"\"\n",
    "    model = MatrixFactorizationWithBiases(\n",
    "        num_users=num_users_train,\n",
    "        num_items=num_items_train,\n",
    "        n_factors=params['n_factors'],\n",
    "        lr=params['lr'],\n",
    "        reg_emb=params['reg_emb'],\n",
    "        reg_bias=0.01,\n",
    "        n_epochs=15,  # для примера\n",
    "        batch_size=1024,\n",
    "        early_stopping_patience=3,\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(train_df, df_val=val_df)\n",
    "    val_rmse = model.evaluate_rmse(val_df)\n",
    "    return val_rmse, model\n",
    "\n",
    "import itertools\n",
    "\n",
    "param_grid = {\n",
    "    'n_factors': range(20, 41, 2),\n",
    "    'lr': np.arange(0.005, 0.011, 0.005),\n",
    "    'reg_emb': np.arange(0.01, 0.06, 0.01)\n",
    "}\n",
    "\n",
    "best_val_rmse = float('inf')\n",
    "best_params   = None\n",
    "best_model    = None\n",
    "\n",
    "for nf, lr, reg in itertools.product(param_grid['n_factors'],\n",
    "                                     param_grid['lr'],\n",
    "                                     param_grid['reg_emb']):\n",
    "    params = {\n",
    "        'n_factors': nf,\n",
    "        'lr': lr,\n",
    "        'reg_emb': reg\n",
    "    }\n",
    "    print(f\"\\n==== Testing: n_factors={nf}, lr={lr}, reg_emb={reg} ====\")\n",
    "    val_rmse, model_ = run_experiment(params)\n",
    "    print(f\"Result val RMSE = {val_rmse:.4f}\")\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_params   = params\n",
    "        best_model    = model_\n",
    "\n",
    "print(\"\\n===== Grid Search Complete =====\")\n",
    "print(f\"Best val RMSE = {best_val_rmse:.4f}\")\n",
    "print(\"Best params:\", best_params)"
   ],
   "id": "e626778b882c8c60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_rmse = best_model.evaluate_rmse(test_data)\n",
    "print(f\"\\n[Best Model] Test RMSE = {test_rmse:.4f}\")\n",
    "\n",
    "def precision_at_k(model, df_test, k=50, rating_threshold=4.0):\n",
    "    user_positive_items = defaultdict(set)\n",
    "    for row in df_test.itertuples():\n",
    "        if row.rating >= rating_threshold:\n",
    "            user_positive_items[row.user_idx].add(row.item_idx)\n",
    "    precisions = []\n",
    "    unique_users_test = df_test['user_idx'].unique()\n",
    "    for u in unique_users_test:\n",
    "        recs = model.recommend_for_user(u, N=k)\n",
    "        hits = sum((itm in user_positive_items[u]) for itm in recs)\n",
    "        prec_u = hits / k\n",
    "        precisions.append(prec_u)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "def recall_at_k(model, df_test, k=50, rating_threshold=3.5):\n",
    "    user_positive_items = defaultdict(set)\n",
    "    for row in df_test.itertuples():\n",
    "        if row.rating >= rating_threshold:\n",
    "            user_positive_items[row.user_idx].add(row.item_idx)\n",
    "    recalls = []\n",
    "    unique_users_test = df_test['user_idx'].unique()\n",
    "    for u in unique_users_test:\n",
    "        recs = model.recommend_for_user(u, N=k)\n",
    "        relevant = user_positive_items[u]\n",
    "        if len(relevant) == 0:\n",
    "            continue\n",
    "        hits = sum((itm in relevant) for itm in recs)\n",
    "        recall = hits / len(relevant)\n",
    "        recalls.append(recall)\n",
    "    if len(recalls) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(recalls)\n",
    "\n",
    "p50  = precision_at_k(best_model, test_data, k=50,  rating_threshold=3.5)\n",
    "p30 = precision_at_k(best_model, test_data, k=30, rating_threshold=3.5)\n",
    "r50  = recall_at_k(best_model, test_data, k=50,  rating_threshold=3.5)\n",
    "r30 = recall_at_k(best_model, test_data, k=30, rating_threshold=3.5)\n",
    "\n",
    "print(f\"Precision@50: {p50:.4f}\")\n",
    "print(f\"Recall@50: {r50:.4f}\")\n",
    "print(f\"Precision@30: {p30:.4f}\")\n",
    "print(f\"Recall@30: {r30:.4f}\")"
   ],
   "id": "673bcf7217516dcb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Визуализация эмбеддингов для пользователей и фильмов",
   "id": "6fb849e34dc93b37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "user_emb = best_model.P  # [num_users, n_factors]\n",
    "item_emb = best_model.Q  # [num_items, n_factors]\n",
    "\n",
    "# 1) UMAP для пользователей\n",
    "umap_users = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "user_2d_umap = umap_users.fit_transform(user_emb)\n",
    "print(\"user_2d_umap shape:\", user_2d_umap.shape)\n",
    "\n",
    "# 2) UMAP для фильмов\n",
    "umap_items = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "item_2d_umap = umap_items.fit_transform(item_emb)\n",
    "print(\"item_2d_umap shape:\", item_2d_umap.shape)\n",
    "\n",
    "# 3) t-SNE для пользователей\n",
    "tsne_users = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "user_2d_tsne = tsne_users.fit_transform(user_emb)\n",
    "print(\"user_2d_tsne shape:\", user_2d_tsne.shape)\n",
    "\n",
    "# 4) t-SNE для фильмов\n",
    "tsne_items = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "item_2d_tsne = tsne_items.fit_transform(item_emb)\n",
    "print(\"item_2d_tsne shape:\", item_2d_tsne.shape)\n",
    "\n",
    "#  Отрисовка UMAP Users \n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(user_2d_umap[:, 0], user_2d_umap[:, 1], c='blue', alpha=0.6)\n",
    "plt.title(\"UMAP - User Embeddings\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.show()\n",
    "\n",
    "#  UMAP Items \n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(item_2d_umap[:, 0], item_2d_umap[:, 1], c='red', alpha=0.6)\n",
    "plt.title(\"UMAP - Item Embeddings\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.show()\n",
    "\n",
    "#  t-SNE Users \n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(user_2d_tsne[:, 0], user_2d_tsne[:, 1], c='blue', alpha=0.6)\n",
    "plt.title(\"t-SNE - User Embeddings\")\n",
    "plt.xlabel(\"t-SNE-1\")\n",
    "plt.ylabel(\"t-SNE-2\")\n",
    "plt.show()\n",
    "\n",
    "#  t-SNE Items \n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(item_2d_tsne[:, 0], item_2d_tsne[:, 1], c='red', alpha=0.6)\n",
    "plt.title(\"t-SNE - Item Embeddings\")\n",
    "plt.xlabel(\"t-SNE-1\")\n",
    "plt.ylabel(\"t-SNE-2\")\n",
    "plt.show()"
   ],
   "id": "25b67c447b7982a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
